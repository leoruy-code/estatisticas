# ğŸ›¡ï¸ Web Scraper Seguro - Guia de Uso

## ğŸ“‹ CaracterÃ­sticas Implementadas

### 1. **Rate Limiting**
- Limite de **15 requests por minuto** (conservador)
- Delay aleatÃ³rio entre **2-5 segundos** entre cada request
- Aguarda automaticamente se atingir o limite

### 2. **Anti-Bloqueio**
```python
âœ… RotaÃ§Ã£o de User-Agents (4 diferentes)
âœ… Headers realistas (Accept, Language, DNT)
âœ… Session persistente com cookies
âœ… Delays aleatÃ³rios
âœ… Retry com backoff exponencial
```

### 3. **Cache Local**
- Cache de **24 horas** para respostas
- Evita requests duplicados
- Armazenado em `data/cache/`

### 4. **Tratamento de Erros**
- **3 tentativas** com retry automÃ¡tico
- Backoff exponencial: 1s â†’ 2s â†’ 4s
- Detecta e aguarda quando recebe `429 Too Many Requests`

## ğŸš€ Como Usar

### Exemplo 1: Buscar fotos de um time
```bash
cd "/Users/leo/RAG ESTATISTICAS"
source venv/bin/activate
python src/atualizar_com_scraper.py Flamengo
```

### Exemplo 2: Buscar fotos de mÃºltiplos times
```bash
python src/atualizar_com_scraper.py Flamengo Palmeiras Corinthians
```

### Exemplo 3: Atualizar TODOS os times
```bash
python src/atualizar_com_scraper.py
```

## âš™ï¸ ConfiguraÃ§Ãµes AjustÃ¡veis

Em `src/scraper_seguro.py`:

```python
# Delays entre requests
MIN_DELAY = 2  # Aumentar para 3-4 se houver bloqueios
MAX_DELAY = 5  # Aumentar para 7-10 se houver bloqueios

# Limite de requests
REQUESTS_PER_MINUTE = 15  # Reduzir para 10 se necessÃ¡rio

# Timeout
TIMEOUT = 30  # Aumentar se conexÃ£o for lenta

# Retries
MAX_RETRIES = 3  # Aumentar para 5 se site for instÃ¡vel
```

## ğŸ“Š Estimativa de Tempo

Para **20 times** (BrasileirÃ£o completo):

| ConfiguraÃ§Ã£o | Tempo Estimado |
|--------------|----------------|
| 15 req/min | ~20-25 minutos |
| 10 req/min | ~30-35 minutos |
| 5 req/min | ~60-70 minutos |

**RecomendaÃ§Ã£o**: Executar em lotes de 5 times por vez.

## ğŸ¯ EstratÃ©gias de Uso

### 1. **Uso Conservador** (Recomendado)
```bash
# Fazer 1 time por vez, verificar se funcionou
python src/atualizar_com_scraper.py Flamengo
python src/atualizar_com_scraper.py Palmeiras
python src/atualizar_com_scraper.py Botafogo
```

### 2. **Uso em Lotes**
```bash
# 5 times por vez (25-30 min cada lote)
python src/atualizar_com_scraper.py Flamengo Palmeiras Botafogo "SÃ£o Paulo" Corinthians
# Aguardar 30-60 minutos antes do prÃ³ximo lote
python src/atualizar_com_scraper.py "AtlÃ©tico-MG" GrÃªmio Fluminense Cruzeiro Vasco
```

### 3. **Uso Automatizado** (Cuidado!)
```bash
# Todos os 20 times de uma vez (~20-25 min total)
# Usar apenas se cache estiver vazio e precisar urgente
python src/atualizar_com_scraper.py
```

## ğŸš¨ Sinais de Bloqueio

Se vocÃª ver:
- âŒ Muitos erros `429 Too Many Requests`
- âŒ Timeouts frequentes
- âŒ Captchas ou redirecionamentos

**SoluÃ§Ã£o**:
1. Parar o script (Ctrl+C)
2. Aguardar 30-60 minutos
3. Aumentar delays: `MIN_DELAY = 4`, `MAX_DELAY = 8`
4. Reduzir taxa: `REQUESTS_PER_MINUTE = 8`
5. Tentar novamente

## ğŸ“ Estrutura do Cache

```
data/cache/
â”œâ”€â”€ a1b2c3d4e5f6.json  # Hash MD5 da URL
â”œâ”€â”€ f6e5d4c3b2a1.json
â””â”€â”€ ...
```

Cada arquivo contÃ©m:
- URL original
- Timestamp
- ConteÃºdo da resposta

**Limpar cache**: `rm -rf data/cache/*`

## ğŸ” Monitoramento

O script mostra em tempo real:
```
âœ… Request #1: https://api.sofascore.com/api/v1/team/5981/players...
ğŸ“¦ Cache hit: https://api.sofascore.com/api/v1/team/5957/players...
â³ Rate limit: aguardando 3.2s...
âš ï¸  Rate limit (429), aguardando 20s...
âœ… Flamengo: foto adicionada
```

## ğŸ’¡ Dicas

1. **Executar em horÃ¡rios fora de pico** (madrugada, fins de semana)
2. **Usar cache ao mÃ¡ximo** - re-executar no mesmo dia usa cache
3. **ComeÃ§ar com 1 time** para testar configuraÃ§Ãµes
4. **Verificar robots.txt**: `curl https://www.sofascore.com/robots.txt`
5. **Alternar fontes** se um site bloquear (transfermarkt, flashscore)

## ğŸ“ Melhores PrÃ¡ticas

### âœ… FAZER:
- Respeitar rate limits
- Usar cache agressivamente
- Adicionar delays
- Rodar em background
- Monitorar logs
- Testar com 1 item primeiro

### âŒ NÃƒO FAZER:
- Fazer milhares de requests seguidos
- Ignorar erros 429
- Usar delays < 1 segundo
- Rodar mÃºltiplas instÃ¢ncias simultaneamente
- Scraping 24/7
- Ignorar robots.txt

## ğŸ› ï¸ Troubleshooting

### Problema: Nenhuma foto encontrada
```bash
# Verificar se o mapeamento estÃ¡ correto
python -c "from src.atualizar_com_scraper import SOFASCORE_TEAMS; print(SOFASCORE_TEAMS['Flamengo'])"

# Testar URL manualmente
curl "https://api.sofascore.com/api/v1/team/5981/players"
```

### Problema: Muitos erros 429
```python
# Em scraper_seguro.py, aumentar delays
MIN_DELAY = 5
MAX_DELAY = 10
REQUESTS_PER_MINUTE = 8
```

### Problema: Cache desatualizado
```bash
# Limpar cache para forÃ§ar novos requests
rm -rf data/cache/*
```

## ğŸ“ˆ PrÃ³ximos Passos

1. âœ… Buscar fotos de jogadores
2. â³ Buscar estatÃ­sticas (gols, assistÃªncias)
3. â³ Buscar ratings do SofaScore
4. â³ Buscar histÃ³rico de partidas
